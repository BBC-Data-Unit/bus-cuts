---
title: "Analysing bus stops data"
output: html_notebook
---

# Analysing bus stops data

This notebook outlines some exploratory analysis of the NaPTAN (National public transport access node) dataset, which shows the locations of bus stops (and other transport points) in the UK.

The latest data is [published by the Department for Transport](https://www.gov.uk/government/publications/national-public-transport-access-node-schema) but [older data from 2010 can also be found on data.gov.uk](https://data.gov.uk/dataset/ff93ffc1-6656-47d8-9155-85ea0b8f2251/national-public-transport-access-nodes-naptan).

***WARNING: the data 'added' on 2010 is actually a link to http://naptan.app.dft.gov.uk/DataRequest/Naptan.ashx?format=csv which provides the latest data, i.e. the same data as on the DfT site.***

Instead, we [find historical data elsewhere on data.gov.uk](https://data.gov.uk/dataset/d1f9e79f-d9db-44d0-b7b1-41c216fe5df6/national-public-transport-data-repository-nptdr)

We have downloaded and unzipped both datasets to the same folder as this notebook. Because the files are named the same we have put them in separate folders:

```{r store folder and file names}
#Store the names of folders so we can generate paths to import etc.
folder10 <- "NaPTANcsv2010"
folder20 <- "NaPTANcsv2020"
folderlist <- c(folder10, folder20)
#Store the names of any files that are in both
stopsfile <- "Stops.csv"
```

[Data on the latest changes made to the data can be found here too](http://naptan.app.dft.gov.uk/Reports/frmStopsSummaryReport). This suggests that, for example, Manchester deleted over a quarter of stops in its latest submission (3/2/20). However, it only goes back a month or so, and it's not possible what the change relates to (e.g. an annual update, or from 10 years ago).

So we want to do that with the two snapshots.

## Import the data 

Now we grab the data in the folders.

```{r import data}
#Install a library for importing data
library(rio)
#import data from path generated by combining folder and file name
stops20 <- rio::import(paste(folder20,stopsfile,sep="/"))
head(stops20)
stops10 <- rio::import(paste(folder10,stopsfile,sep="/"))
head(stops10)
```

And get an overview. The [schema](http://naptan.dft.gov.uk/naptan/schema/2.5/doc/NaPTANSchemaGuide-2.5-v0.67.pdf) is in a PDF called `NaPTANSchemaGuide-2.5-v0.67.pdf` saved to this folder. 

```{r colnames}
colnames(stops20)
```

Here's a statistical summary.

```{r summary}
summary(stops20)
```

One column looks interesting 

```{r table busstoptype}
table(stops20$BusStopType)
```

The hunch might be that blank ones are not bus stops.

```{r create subset where no bus stop type}
nobustype <- subset(stops20, stops20$BusStopType == "")
head(nobustype)
```

It does look like it. We can see if another column helps

```{r table stoptype}
table(stops20$StopType)
table(nobustype$StopType)
```

The BCT type - easily the largest - is missing from the subset. This does match with the schema which shows the 4 bus stop types (not including OTH) under the BCT code, which means 'busCoachTrolleyStopOnStreet'

BCE is a bus or coach station entrance ('busCoachStationEntrance'), so we want to include that in our analysis. BCQ ('busCoachTrolleyStation-VariableBay') and BCS ('busCoachTrolleyStationBay') is a bay/pole within a station. BST ('busCoachAccess') is the access area. 

However bus stop type MKD is used for all so we can still look for those with that.

The NaptanCode looks useful but a look at the schema suggests it doesn't include any characters that refer to type of stop. It has two parts:

> o A one or three character area AlphaPrefix prefix, chosen ideally to have mnemonic relevance to the administrative area name of the locality, and using any of the letters (or numbers) mapped to a given key. For example, sur for Surrey. London is treated as a special case and has a one character prefix of ‘1’. All other areas use a three character all alpha or all numeric code which cannot begin with 0 or 1.
> o Three to five character (letters or numbers) stop reference unique within the area grouping, for example dagm, ‘7456’. The choice of letters or numbers is made by
each administrative area.

## Compare datasets

Each dataset had the same number of rows when we first downloaded them. Let's check again:

```{r nrow}
nrow(stops10)
nrow(stops20)
```

If we did need to confirm they were the same dataset we would use the code below.

```{r compare datasets, eval=FALSE, include=FALSE}
#Check cells against each other to see if they are *different* - easier to count TRUEs then
aretheythesame <- stops10 != stops20
#How many are TRUE
sum(aretheythesame, na.rm = T)
#Remove data
rm(aretheythesame)
```

We can create a merged dataset which shows the status in 2010 and in 2020

```{r}
stops10and20 <- merge(stops10, stops20, by = 'ATCOCode')
```


## When were stops deleted?

We could not compare 2010 with 2020 directly but we *could* see when changes were made to the data because each row contains information on whether the stop is active or not, and when that change was made.

```{r modification table}
table(stops20$Modification)
```

So the modifications made include 98,000 new entires and 21,000 deletions, but most were revisions.

```{r status table}
table(stops20$Status)
```

And about 51,000 are deleted.

```{r summary moddatetime}
summary(stops20$ModificationDateTime)
```

### Extract modification years

We need to convert those character strings to actual datetime objects - or just extract the years.

```{r substr year}
#You extract the year by grabbing the first 4 characters with substr
substr("2017-07-17T14:41:57",0,4)
#Do this to a whole column and you get a vector, which can be added as a new column
stops20$modyear <- substr(stops20$ModificationDateTime,0,4)
#Show a summary
table(stops20$modyear)
```

A quick glance suggests that most modifications were made in 2016 and 2011

### Create a bus subset

We can now create a subset for just bus stops

```{r bus subset}
busstops20 <- subset(stops20, stops20$BusStopType != "")
```


## Query: which modifications in which years

Let's generate a table which shows, for each year, how many of each type of modification were made - was 2016 all deletions, or additions? 

```{r sqldf query}
#Activate the sqldf package
library(sqldf)
#Query the dataset and store in dataframe
modsquery <- sqldf::sqldf("SELECT modyear, Modification, count(*) AS modscount
             FROM busstops20
             GROUP BY modyear, Modification
             ORDER BY modyear DESC")
#Show results
modsquery
```

Can we calculate an overall change (additions minus deletions)?

First we need to clean the data frame so that each year is just one row, and we have columns for each modification type.

We use the tidyr package for this.

```{r tidyr spread}
#Activate tidyverse
library(tidyverse)
#Spread from a narrow table to a wider one
#Modification is the column we want to spread out, and modscount has the values we want to transfer with it.
modsqueryspread <- tidyr::spread(modsquery, Modification, modscount)
#Show results
modsqueryspread
```

We have a weird V1 column which is dirty data.

```{r remove dirty cols and rows}
#Remove dirty cols
modsqueryspread$V1 <- NULL
#Remove the blank year and 1899 row
modsqueryspread <- subset(modsqueryspread, modsqueryspread$modyear != "")
modsqueryspread <- subset(modsqueryspread, modsqueryspread$modyear != "1899")
#Show cleaned result
modsqueryspread
```

Now to calculate the changes in each year

```{r add col for change}
#New stops minus deleted stops
modsqueryspread$change <- modsqueryspread$new - modsqueryspread$del
#Show results
modsqueryspread
```

```{r write csv}
write.csv(modsqueryspread, "stopchanges.csv")
```

The big problem with this data is that we seem to be only looking at the latest modification - so for example a stop which was added ('new') in 2015 but then deleted in 2019 will only show up as deleted in 2019. This is why there are fewer 'new' stops the further back you go (it is more likely that some other modification was made since).

So an analysis of new stops minus deleted stops in any given year is, strictly speaking, an analysis of stops which were added but *have not been modified since that year* compared to stops which were deleted but *not modified since*.

To illustrate this, the column RevisionNumber shows which revision this is - we can see how that varies:

```{r summary revision number}
summary(busstops20$RevisionNumber)
```

So average stop has been revised more than 8 times (or twice if you use the median) and a quarter of stops have been revised 4 times or more. One stop has been revised 628 times.

## Looking at stop status

Let's look at the current status of bus stops.

```{r table bus stop status}
table(busstops20$Status)
```

Perhaps one in nine bus stops are deleted

```{r calculate perc}
#Part divided by whole
48401/(369561+48401)
```

Is there regional variation?

```{r table of locality name}
table(busstops20$GrandParentLocalityName)
```

Let's query against that column.

```{r sqldf group by locality and status}
sqldf::sqldf("SELECT Status, GrandParentLocalityName, count(*) AS stopcount
             FROM busstops20
             GROUP BY GrandParentLocalityName, Status
             ORDER BY stopcount DESC")
```

Too many blanks. Let's try another.

```{r sqldf count by AdministrativeAreaCode and status}
stopbyarea <- sqldf::sqldf("SELECT Status, AdministrativeAreaCode, count(*) AS stopcount
             FROM busstops20
             GROUP BY AdministrativeAreaCode, Status
             ORDER BY stopcount DESC")
stopbyarea
```

Better.

And clean.

```{r tidyr spread stops by area}
#Spread from a narrow table to a wider one
#Modification is the column we want to spread out, and modscount has the values we want to transfer with it.
stopbyareaspread <- tidyr::spread(stopbyarea, Status, stopcount)
#Show results
stopbyareaspread
```

We have those admin codes in an [old Guardian Datablog story](https://www.theguardian.com/news/datablog/2010/sep/27/uk-transport-national-public-data-repository#data) about the NaPTAN data.

I've scraped that table into a Google Sheet and downloaded it. Now we import it.

```{r import admincodes}
admincodes <- rio::import("naptanadmincodes.csv")
head(admincodes)
```

And merge.

```{r merge data}
stopbyareamerge <- merge(stopbyareaspread, admincodes, by.x = 'AdministrativeAreaCode', by.y = 'Admin Code')
stopbyareamerge
```

What's quite good here is that we can actually compare the 2010 figure with the latest ones:

```{r}
colnames(stopbyareamerge)
```

```{r calculate change 10 to 20}
#Combine all the different statuses - we don't know if the Guardian story was just active ones
stopbyareamerge$total <- stopbyareamerge$act+stopbyareamerge$del
#Calculate a change of active ones
stopbyareamerge$change10to20 <- stopbyareamerge$`Bus and coach stops` - stopbyareamerge$act 
stopbyareamerge$change10to20all <- stopbyareamerge$`Bus and coach stops` - stopbyareamerge$total
```

```{r sqldf to show change}
sqldf::sqldf("SELECT act-`Bus and coach stops` AS change10to20, AreaName, act AS active2020, total AS all20, `Bus and coach stops` AS fig2010
             FROM stopbyareamerge
             ORDER BY change10to20 ASC")
```

```{r}
head(stops10and20)
stops10and20$
```

